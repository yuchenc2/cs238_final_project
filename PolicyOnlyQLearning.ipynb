{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def q_learning_fixed_with_default_action(data, alpha=0.1, gamma=1, epsilon=0.1, default_action='No Training'):\n",
    "    \"\"\"\n",
    "    Perform Q-learning on the given dataset and calculate the policy,\n",
    "    defaulting to a specific action when no actions are available in the Q-table.\n",
    "    \"\"\"\n",
    "    q_table = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for epoch in range(500):\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch)\n",
    "        for i in range(len(data)):\n",
    "            sample_row = data.iloc[i]\n",
    "            state = (sample_row['Job Title Numeric'], sample_row['Years of Experience in Months'], \n",
    "                    sample_row['P_Score'], sample_row['C_Rating'])\n",
    "            action = sample_row['Training Program']\n",
    "            reward = sample_row['Reward']\n",
    "            next_state = (sample_row['Job Title Numeric'], sample_row['Next Years of Experience in Months'], \n",
    "                        sample_row['Next P_Score'], sample_row['Next C_Rating'])\n",
    "\n",
    "            old_value = q_table[state][action]\n",
    "            next_max = np.max(list(q_table[next_state].values())) if q_table[next_state] else 0\n",
    "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            q_table[state][action] = new_value\n",
    "\n",
    "    optimal_policy = {}\n",
    "    for state in q_table:\n",
    "        if q_table[state]:\n",
    "            best_action = max(q_table[state], key=q_table[state].get)\n",
    "            optimal_policy[state] = best_action\n",
    "        else:\n",
    "            optimal_policy[state] = default_action\n",
    "\n",
    "    return q_table, optimal_policy\n",
    "\n",
    "def sarsa_with_default_action(data, alpha=0.1, gamma=1, epsilon=0.1, default_action='No Training'):\n",
    "    \"\"\"\n",
    "    Perform SARSA on the given dataset and calculate the policy,\n",
    "    defaulting to a specific action when no actions are available in the Q-table.\n",
    "    \"\"\"\n",
    "    q_table = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "    for epoch in range(500):\n",
    "        if epoch % 10 == 0:\n",
    "            print(epoch)\n",
    "        \n",
    "        for i in range(len(data) - 1):  # Loop over data, leaving the last row for terminal state\n",
    "            sample_row = data.iloc[i]\n",
    "            next_row = data.iloc[i + 1]\n",
    "\n",
    "            # Current state and action\n",
    "            state = (sample_row['Job Title Numeric'], sample_row['Years of Experience in Months'], \n",
    "                     sample_row['P_Score'], sample_row['C_Rating'])\n",
    "            action = sample_row['Training Program']\n",
    "\n",
    "            # Next state and action (using next row in the data)\n",
    "            next_state = (next_row['Job Title Numeric'], next_row['Years of Experience in Months'], \n",
    "                          next_row['Next P_Score'], next_row['Next C_Rating'])\n",
    "            next_action = next_row['Training Program'] if (i < len(data) - 1) else default_action\n",
    "\n",
    "            # SARSA update rule\n",
    "            reward = sample_row['Reward']\n",
    "            old_value = q_table[state][action]\n",
    "            next_value = q_table[next_state][next_action]\n",
    "            new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_value)\n",
    "            q_table[state][action] = new_value\n",
    "\n",
    "    # Determine the optimal policy from the Q-table\n",
    "    optimal_policy = {}\n",
    "    for state in q_table:\n",
    "        if q_table[state]:\n",
    "            best_action = max(q_table[state], key=q_table[state].get)\n",
    "            optimal_policy[state] = best_action\n",
    "        else:\n",
    "            optimal_policy[state] = default_action\n",
    "\n",
    "    return q_table, optimal_policy\n",
    "\n",
    "# Note: This function assumes the dataset is ordered such that consecutive rows represent\n",
    "# consecutive steps in an episode. If this is not the case, additional logic will be needed\n",
    "# to correctly pair states and actions.\n",
    "\n",
    "\n",
    "\n",
    "def calculate_average_policy_value(q_table, initial_states, gamma=0.9, max_steps=100):\n",
    "    \"\"\"\n",
    "    Calculate the average value of the policy over a set of initial states, using the Q-table.\n",
    "    \"\"\"\n",
    "    total_values = []\n",
    "\n",
    "    for initial_state in initial_states:\n",
    "        total_reward = 0\n",
    "        current_state = initial_state\n",
    "        for step in range(max_steps):\n",
    "            best_action = None\n",
    "            best_q_value = float('-inf')\n",
    "            for action, q_value in q_table[current_state].items():\n",
    "                if q_value > best_q_value:\n",
    "                    best_q_value = q_value\n",
    "                    best_action = action\n",
    "\n",
    "            if best_action is None:\n",
    "                break\n",
    "\n",
    "            total_reward += (gamma ** step) * best_q_value\n",
    "            current_state = tuple(x + 1 for x in current_state)\n",
    "        total_values.append(total_reward)\n",
    "\n",
    "    return sum(total_values) / len(total_values) if total_values else 0\n",
    "\n",
    "def calculate_random_policy_value(data, initial_states, gamma=0.9, max_steps=100):\n",
    "    \"\"\"\n",
    "    Calculate the average value of a random policy over a set of initial states.\n",
    "    \"\"\"\n",
    "    total_values = []\n",
    "\n",
    "    for initial_state in initial_states:\n",
    "        total_reward = 0\n",
    "        current_state = initial_state\n",
    "        for step in range(max_steps):\n",
    "            available_actions = data[data['Job Title Numeric'] == current_state[0]]['Training Program'].unique()\n",
    "            if not len(available_actions):\n",
    "                break\n",
    "\n",
    "            action = random.choice(available_actions)\n",
    "            sample_row = data[(data['Job Title Numeric'] == current_state[0]) & \n",
    "                            (data['Training Program'] == action)].sample(n=1)\n",
    "            reward = sample_row['Reward'].iloc[0]\n",
    "\n",
    "            total_reward += (gamma ** step) * reward\n",
    "            current_state = tuple(x + 1 for x in current_state)\n",
    "        total_values.append(total_reward)\n",
    "\n",
    "    return sum(total_values) / len(total_values) if total_values else 0\n",
    "\n",
    "# First, I will load and inspect the contents of the provided dataset to understand its structure and the data available.\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/Users/aditribhagirath/Desktop/mediumjob.csv'\n",
    "data = pd.read_csv(file_path, delimiter='\\t')\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataset to understand its structure\n",
    "#print(data.head())\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "q_table, optimal_policy = sarsa_with_default_action(data)\n",
    "sample_initial_states = list(q_table.keys())\n",
    "learned_policy_value = calculate_average_policy_value(q_table, sample_initial_states)\n",
    "random_policy_value = calculate_random_policy_value(data, sample_initial_states)\n",
    "print(learned_policy_value, random_policy_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
